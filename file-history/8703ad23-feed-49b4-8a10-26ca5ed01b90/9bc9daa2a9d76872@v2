# Stagehand Analysis for Insurance Form Automation

**Date**: 2025-10-16
**Repository**: https://github.com/browserbase/stagehand-python
**Version Analyzed**: main branch (latest)

---

## Executive Summary

**Recommendation**: **NOT compatible** with project requirements

**Core Incompatibility**: Stagehand requires runtime LLM inference for every automation run, fundamentally conflicting with the spec-driven, deterministic approach defined in project specifications.

---

## Architecture Analysis

### What Stagehand Actually Is

Stagehand is an **AI-native browser automation framework** that wraps Playwright and uses Large Language Models to dynamically generate Playwright commands at runtime.

**Key Components**:
1. Playwright Page wrapper (`StagehandPage`)
2. LLM inference engine (`llm/inference.py`)
3. Three primary APIs: `act()`, `extract()`, `observe()`
4. Optional API mode (Browserbase hosted) or LOCAL mode

### Runtime LLM Requirement

**Evidence from code analysis**:

```python
# stagehand/handlers/observe_handler.py:77
observation_response = await observe_inference(
    instruction=instruction,
    tree_elements=output_string,
    llm_client=self.stagehand.llm,  # LLM client required
    ...
)
```

```python
# stagehand/config.py:89
model_name: Optional[str] = Field(
    AvailableModel.GPT_4O,  # Defaults to GPT-4O
    alias="modelName"
)
```

```python
# examples/quickstart.py:26-27
model_name="google/gemini-2.5-flash-preview-05-20",
model_client_options={"apiKey": os.getenv("MODEL_API_KEY")},
```

**Findings**:
- Every `act()`, `observe()`, `extract()` call makes LLM API request
- Model API key required (OpenAI, Anthropic, Google)
- Token usage tracked and logged
- Default model: GPT-4O

---

## Feature Comparison Matrix

| Feature | Stagehand | Project Requirements | Compatible? |
|---------|-----------|---------------------|-------------|
| **Selector Strategy** | LLM generates selectors at runtime | ARIA labels from specifications | ❌ |
| **Fallback Logic** | Self-healing enabled by default | Explicitly prohibited ("no failsafe/fallover") | ❌ |
| **Determinism** | Non-deterministic (LLM responses vary) | Deterministic spec-driven execution | ❌ |
| **Runtime Dependencies** | LLM API key + inference | No runtime LLM, specs only | ❌ |
| **Wait Strategies** | Smart DOM settling (`_wait_for_settled_dom`) | Explicit waits from specs | ✅ (Could use) |
| **Artifacts** | Basic (no comprehensive capture) | Screenshots, HAR, trace, ARIA, telemetry | ⚠️ (Partial) |
| **Playwright Version** | Uses Playwright (unspecified version) | Playwright 1.55.0+ verified | ✅ |
| **Cost Model** | Pay-per-run (LLM API costs) | One-time spec creation cost | ❌ |

---

## Detailed Analysis Against Requirements

### 1. Two-Phase Strategy (Reconnaissance → Automation)

**Project Approach**:
- Phase 1: `reconnaissance.py` - Capture form structure without LLM
- Phase 2: `fill_par_form.py` - Execute based on static specifications

**Stagehand Approach**:
- Single phase: Every run calls LLM to understand page
- `observe()` can cache results, but still requires LLM on first run
- No static specification format

**Verdict**: ❌ Incompatible - Stagehand doesn't support spec-driven execution

---

### 2. "No Failsafe and No Fallover" Constraint

**Project Requirement**:
```yaml
# From clarification cycle 2
Constraint: No selector fallbacks or retry logic - explicit waits only
```

**Stagehand Behavior**:
```python
# stagehand/config.py:92-94
self_heal: Optional[bool] = Field(
    True,  # ENABLED BY DEFAULT
    alias="selfHeal",
    description="Enable self-healing functionality"
)
```

**Quote from Stagehand docs**:
> "The code is self-healing since it's dynamically generating Playwright every time, making it much more resilient to minor DOM changes."

**Verdict**: ❌ Directly contradicts requirement - self-healing is core feature

---

### 3. Spec-Driven Field Mapping

**Project Specifications** (`manulife-par-form.yaml`):
```yaml
properties:
  first_name:
    type: string
    x-aria-label: "First name"
    x-timeout: 15000
```

**Stagehand Approach**:
```python
await page.act("click on the 'Quickstart' button")  # Natural language
await page.observe("find the search bar")           # LLM interprets
```

**Verdict**: ❌ No spec format - requires natural language instructions

---

### 4. Dynamic Form Handling with Explicit Waits

**Project Approach**:
```yaml
# From CLAUDE.md
x-wait-strategy: networkidle | api-response | visible
x-timeout: 15000
```

**Stagehand Implementation**:
```python
# stagehand/page.py:505-537
async def _wait_for_settled_dom(self, timeout_ms: int = None):
    """
    Wait for the DOM to settle (stop changing) before proceeding.

    Definition of "settled":
    • No in-flight network requests (except WebSocket / Server-Sent-Events).
    • That idle state lasts for at least 500 ms (the "quiet-window").
    """
```

**Verdict**: ⚠️ Partial compatibility - DOM settling logic is reusable, but tightly coupled to Stagehand client

---

### 5. Environment-Controlled Submission

**Project Requirement**:
```bash
export SUBMIT=true   # Opt-in for actual submission
export SUBMIT=false  # Dry-run mode
```

**Stagehand**:
- No built-in dry-run mode
- Every `act("submit form")` executes immediately
- Would need custom wrapper logic

**Verdict**: ⚠️ Not supported - requires custom implementation

---

### 6. Artifact Capture for Analysis

**Project Requirements**:
```
artifacts/YYYY-MM-DD_HH-MM-SS/
├── 001_initial.png
├── 002_filled.png
├── 003_submitted.png
├── 002_filled.dom.html
├── 003_submitted.dom.html
├── aria_002.yaml
├── aria_003.yaml
├── session.har
├── trace.zip
├── telemetry.ndjson
└── index.json
```

**Stagehand Artifacts**:
- Basic logging
- Metrics (token usage, inference time)
- No comprehensive artifact capture built-in
- Access to underlying Playwright page for manual capture

**Verdict**: ⚠️ Requires significant custom implementation

---

## Cost Analysis

### Stagehand Costs (Per Run)

**LLM API Costs** (assuming GPT-4O):
- observe() call: ~500-1000 tokens input (accessibility tree)
- act() call: ~500-1000 tokens input
- extract() call: ~1000-2000 tokens input

**Example form automation** (10 fields):
- 10 × act() calls = 5,000-10,000 input tokens
- 1 × observe() preview = 500-1,000 tokens
- Estimated cost per run: $0.05-$0.15 (GPT-4O pricing)

**Annual cost** (1 run/day):
- ~$18-$55/year in LLM API costs alone

### Project Approach Costs

**One-Time Costs**:
- Reconnaissance phase: Manual analysis (1-2 hours)
- Specification creation: Document findings (1 hour)
- Script development: Implementation (2-4 hours)

**Per-Run Costs**:
- $0 (no LLM inference)
- Playwright execution only

**Verdict**: Project approach is more cost-effective for repeated automation

---

## Specific Stagehand Features Analysis

### 1. `observe()` - AI Element Discovery

**How it works**:
1. Extracts accessibility tree from page
2. Sends to LLM with natural language instruction
3. LLM identifies elements matching instruction
4. Returns `ObserveResult` with selector + method

**Example**:
```python
result = await page.observe("find the email input field")
# Returns: ObserveResult(selector="xpath=...", method="fill", ...)
```

**Caching**:
```python
# First run: LLM inference
email_field = await page.observe("find the email input field")

# Subsequent runs: reuse cached result (but INITIAL run still needs LLM)
await page.act(email_field)  # Uses cached selector
```

**Verdict**: Useful for discovery, but incompatible with spec-driven approach

---

### 2. `act()` - AI Action Execution

**How it works**:
1. Accepts natural language instruction OR ObserveResult
2. If string: calls LLM to generate Playwright command
3. If ObserveResult: uses cached selector directly
4. Executes action

**Self-Healing Behavior**:
```python
# stagehand/config.py
self_heal: True  # Default

# If action fails, Stagehand retries with LLM regeneration
```

**Verdict**: Self-healing violates "no failover" constraint

---

### 3. `extract()` - Structured Data Extraction

**How it works**:
1. Accepts Pydantic schema + natural language instruction
2. Sends page content + schema to LLM
3. LLM extracts data matching schema
4. Returns validated Pydantic model

**Use case**: Data extraction, not form automation

**Verdict**: Not relevant for form filling

---

### 4. DOM Settling Logic

**Implementation** (`page.py:505-713`):
- Monitors CDP Network events
- Tracks in-flight requests
- Removes stalled document requests after 2s
- Resolves after 500ms quiet window

**Verdict**: ✅ High-quality implementation, but tightly coupled

---

## Could Stagehand Components Be Extracted?

### Potentially Reusable

1. **DOM Settling Logic** (`_wait_for_settled_dom`)
   - High-quality network idle detection
   - Could extract to standalone utility
   - Effort: Medium (needs decoupling from StagehandPage)

2. **Accessibility Tree Extraction** (`a11y/utils.py`)
   - Generates simplified DOM representation
   - Could inform reconnaissance phase
   - Effort: Low

3. **CDP Session Management** (`page.py:444-503`)
   - Persistent CDP client handling
   - Useful for advanced Playwright usage
   - Effort: Low

### Not Reusable

1. **LLM Inference Engine** - Core dependency on runtime LLM
2. **Self-Healing Logic** - Violates constraints
3. **act/observe/extract APIs** - Natural language, not spec-driven

---

## Alternative: Use Stagehand for Reconnaissance Only?

### Hypothetical Workflow

1. Use Stagehand's `observe()` to discover form fields
2. Export results to project specification format
3. Implement `fill_par_form.py` using exported specs

### Challenges

1. **License compatibility**: Stagehand is MIT (compatible)
2. **Dependency weight**: Heavy dependencies (litellm, browserbase SDK)
3. **Over-engineering**: Manual reconnaissance already planned
4. **API key requirement**: Still needs LLM API for discovery phase

### Verdict

Not recommended - manual reconnaissance with Playwright trace viewer provides same information without dependencies.

---

## Final Verdict

### Should Stagehand Be Used?

**NO** - for the following reasons:

1. **Architectural Mismatch**: AI-driven vs spec-driven approaches are fundamentally incompatible
2. **Constraint Violations**: Self-healing and fallback logic violate "no failover" requirement
3. **Runtime LLM Dependency**: Every run requires LLM API key + inference costs
4. **Non-Determinism**: LLM responses vary, violating deterministic execution requirement
5. **No Spec Format**: Natural language instructions incompatible with OpenAPI 3.1.0 specifications
6. **Cost Model**: Ongoing per-run costs vs one-time specification creation

### What Stagehand Solves (That You Don't Need)

- **Adaptive automation for unknown pages** → You have specific form URL
- **Self-healing for DOM changes** → You explicitly want fail-fast behavior
- **Natural language interface** → You want explicit specifications
- **Cross-site generalization** → You target single Manulife form

### What You Actually Need (That Stagehand Doesn't Provide)

- **Spec-driven execution from YAML** → Stagehand uses natural language
- **Deterministic behavior** → Stagehand is non-deterministic (LLM variance)
- **Comprehensive artifacts** → Stagehand lacks artifact capture
- **Zero runtime LLM costs** → Stagehand requires LLM every run
- **Environment-controlled submission** → Stagehand lacks dry-run mode

---

## Recommendations

### 1. Proceed with Original Plan

Continue with two-phase approach:
- `reconnaissance.py` - Playwright trace + manual analysis
- `fill_par_form.py` - Spec-driven automation

**Rationale**: Aligns with all requirements, no compromises needed

### 2. Optional: Extract DOM Settling Logic

If time permits, consider extracting Stagehand's `_wait_for_settled_dom` logic:

```python
# Create standalone utility
from stagehand.page import StagehandPage

async def wait_for_network_idle(page: Page, timeout_ms: int = 30000):
    """
    Standalone version of Stagehand's DOM settling logic.

    Monitors CDP Network events and resolves after 500ms quiet window.
    """
    # Adapted from stagehand/page.py:505-713
    # Remove Stagehand client dependencies
    # Return simple async function
```

**Effort**: 1-2 hours
**Benefit**: Production-grade network idle detection
**Risk**: Low - pure utility function

### 3. Monitor Stagehand Evolution

Stagehand is actively developed - watch for:
- Static specification support
- Deterministic mode flag
- Artifact capture features

**Timeline**: Check back in 6 months (2025 Q2)

---

## Corrections to User Assumptions

### Assumption: "Will this be of any help?"

**Correction**: No, Stagehand will not help for this specific project due to:
1. Architectural incompatibility (AI-driven vs spec-driven)
2. Constraint violations (self-healing vs fail-fast)
3. Cost model mismatch (per-run vs one-time)

### Potential Confusion: "Self-Healing" Marketing

Stagehand's marketing emphasizes "resilience" and "self-healing" as positive features. However, for your use case:
- Self-healing = unwanted fallback logic
- Resilience = unwanted retry behavior
- Adaptive = unwanted non-determinism

**These are features to avoid, not benefits to seek.**

---

## Conclusion

Stagehand is a well-engineered AI-native automation framework solving a different problem than your insurance form automation project. It excels at:
- Automating unfamiliar websites without upfront analysis
- Adapting to DOM changes across runs
- Natural language automation interfaces

Your project requires:
- Deterministic execution from static specifications
- Fail-fast behavior with comprehensive artifacts
- Zero-cost repeated execution

**Recommendation**: Do not use Stagehand. Proceed with original two-phase Playwright approach as specified.

---

**Analysis Version**: 1.0.0
**Stagehand Commit Analyzed**: Latest main branch (2025-10-16)
**Reviewer**: Claude Code AI Assistant
