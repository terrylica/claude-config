#!/usr/bin/env python3
"""
Comprehensive audit of delta-neutral funding rate arbitrage backtesting.

Validates:
1. 1-min bar construction from raw ticks
2. Price alignment and timing assumptions
3. Delta-neutral P&L calculation
4. Funding rate vs. market P&L separation
5. Common pitfalls in arbitrage backtesting
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import sys

# Add libs to path
sys.path.insert(0, str(Path(__file__).parent / 'libs' / 'okx-price-provider' / 'src'))
from okx_price_provider import BarPriceProvider

print("="*80)
print("COMPREHENSIVE BACKTEST AUDIT")
print("="*80)
print()

# ============================================================================
# 1. VERIFY 1-MIN BAR CONSTRUCTION
# ============================================================================
print("1. VERIFYING 1-MIN BAR CONSTRUCTION")
print("-" * 80)

bars_dir = Path('data/1min_bars')
ticks_dir = Path('data/raw_ticks')

if not bars_dir.exists():
    print(f"ERROR: Bars directory not found: {bars_dir}")
    sys.exit(1)

# Sample check: Jan 2023
sample_bars = bars_dir / '2023' / '01.parquet'
sample_ticks = ticks_dir / '2023' / '01.parquet'

if not sample_bars.exists() or not sample_ticks.exists():
    print(f"ERROR: Sample files not found")
    sys.exit(1)

print(f"✓ Loading sample bars: {sample_bars}")
bars_df = pd.read_parquet(sample_bars)
print(f"  Bars: {len(bars_df):,} records")
print(f"  Columns: {list(bars_df.columns)}")
print(f"  Symbols: {bars_df['symbol'].nunique()}")

print()
print(f"✓ Loading sample ticks: {sample_ticks}")
ticks_df = pd.read_parquet(sample_ticks)
print(f"  Ticks: {len(ticks_df):,} records")
print(f"  File size: {sample_ticks.stat().st_size / 1024**2:.1f} MB")

# Check OHLCV integrity
print()
print("Checking OHLCV integrity...")
sample_symbol = bars_df['symbol'].iloc[0]
symbol_bars = bars_df[bars_df['symbol'] == sample_symbol].head(100)

# Verify OHLC relationships
invalid_ohlc = symbol_bars[
    (symbol_bars['high'] < symbol_bars['low']) |
    (symbol_bars['high'] < symbol_bars['open']) |
    (symbol_bars['high'] < symbol_bars['close']) |
    (symbol_bars['low'] > symbol_bars['open']) |
    (symbol_bars['low'] > symbol_bars['close'])
]

if len(invalid_ohlc) > 0:
    print(f"  ⚠ WARNING: Found {len(invalid_ohlc)} bars with invalid OHLC relationships")
else:
    print(f"  ✓ All OHLC relationships valid (High >= Low, High >= Open/Close, etc.)")

# Check for gaps in timestamps
print()
print("Checking timestamp continuity...")
symbol_bars = symbol_bars.sort_values('timestamp')
time_diffs = symbol_bars['timestamp'].diff().dt.total_seconds() / 60  # Convert to minutes
expected_gaps = time_diffs[time_diffs > 1.5]  # Allow 50% tolerance
if len(expected_gaps) > 0:
    print(f"  ⚠ Found {len(expected_gaps)} gaps > 1.5 min in timestamps")
    print(f"    Max gap: {time_diffs.max():.1f} minutes")
else:
    print(f"  ✓ Timestamps are continuous (1-min intervals)")

print()
print("-" * 80)

# ============================================================================
# 2. VALIDATE PRICE PROVIDER BEHAVIOR
# ============================================================================
print()
print("2. VALIDATING PRICE PROVIDER BEHAVIOR")
print("-" * 80)

provider = BarPriceProvider(bars_dir)
print("✓ BarPriceProvider initialized")

# Test timestamp flooring behavior
test_time = "2023-01-01 00:00:01"  # 1 second after midnight
print(f"\nTesting timestamp flooring at {test_time}...")

# Get price for BTC-USDT
try:
    prices = provider.get_prices(
        symbols=['BTC-USDT'],
        start_date=test_time,
        end_date=test_time,
        freq='1min',
        method='vwap'
    )
    if len(prices) > 0:
        actual_time = prices['timestamp'].iloc[0]
        price = prices['price'].iloc[0]
        print(f"  ✓ Query at {test_time} → returned bar at {actual_time}")
        print(f"    Price: ${price:,.2f}")

        # Verify it floors to the minute
        expected_floor = pd.to_datetime(test_time).floor('1min')
        if actual_time == expected_floor:
            print(f"  ✓ Correctly floored to minute boundary")
        else:
            print(f"  ⚠ WARNING: Did not floor correctly!")
            print(f"    Expected: {expected_floor}")
            print(f"    Got: {actual_time}")
    else:
        print(f"  ⚠ WARNING: No price returned!")
except Exception as e:
    print(f"  ⚠ ERROR: {e}")

print()
print("-" * 80)

# ============================================================================
# 2B. VALIDATE SPOT-PERP PRICE ALIGNMENT
# ============================================================================
print()
print("2B. VALIDATING SPOT-PERP PRICE ALIGNMENT")
print("-" * 80)

# Check that spot and perp have synchronized timestamps
print("\nChecking spot-perp timestamp synchronization...")

# Get spot and perp symbols
spot_symbols = bars_df[bars_df['symbol'].str.endswith('-USDT') &
                       ~bars_df['symbol'].str.endswith('-SWAP')]['symbol'].unique()
perp_symbols = bars_df[bars_df['symbol'].str.endswith('-SWAP')]['symbol'].unique()

print(f"  Spot symbols: {len(spot_symbols):,}")
print(f"  Perp symbols: {len(perp_symbols):,}")

# Check timestamp alignment for a sample (BTC)
if 'BTC-USDT' in bars_df['symbol'].values and 'BTC-USDT-SWAP' in bars_df['symbol'].values:
    btc_spot = bars_df[bars_df['symbol'] == 'BTC-USDT'].copy()
    btc_perp = bars_df[bars_df['symbol'] == 'BTC-USDT-SWAP'].copy()

    # Find common timestamps
    spot_times = set(btc_spot['timestamp'])
    perp_times = set(btc_perp['timestamp'])
    common_times = spot_times & perp_times

    coverage = len(common_times) / max(len(spot_times), len(perp_times)) * 100

    print(f"\nBTC-USDT alignment analysis:")
    print(f"  Spot bars: {len(btc_spot):,}")
    print(f"  Perp bars: {len(btc_perp):,}")
    print(f"  Common timestamps: {len(common_times):,}")
    print(f"  Timestamp coverage: {coverage:.1f}%")

    if coverage >= 99:
        print(f"  ✓ Excellent spot-perp alignment (>99%)")
    elif coverage >= 95:
        print(f"  ✓ Good spot-perp alignment (95-99%)")
    else:
        print(f"  ⚠ WARNING: Poor alignment ({coverage:.1f}%)")
        print(f"    This could cause hedging errors!")

    # Check price correlation (should be very high for proper hedging)
    if coverage > 0:
        merged = btc_spot.merge(btc_perp, on='timestamp', suffixes=('_spot', '_perp'))
        price_corr = merged['close_spot'].corr(merged['close_perp'])
        print(f"\n  Spot-perp price correlation: {price_corr:.6f}")

        if price_corr > 0.9999:
            print(f"  ✓ Excellent price tracking (>0.9999)")
        elif price_corr > 0.999:
            print(f"  ✓ Good price tracking (>0.999)")
        else:
            print(f"  ⚠ WARNING: Unexpected correlation ({price_corr:.6f})")
else:
    print("\n  ⚠ Could not find BTC-USDT/SWAP data for alignment check")

print()
print("-" * 80)

# ============================================================================
# 3. AUDIT DELTA-NEUTRAL CALCULATIONS
# ============================================================================
print()
print("3. AUDITING DELTA-NEUTRAL CALCULATIONS")
print("-" * 80)

# Load backtest results
results_file = Path('results/v1.9-modular-20230101-20250831.parquet')
if not results_file.exists():
    print(f"⚠ WARNING: Results file not found: {results_file}")
else:
    print(f"✓ Loading backtest results: {results_file}")
    results = pd.read_parquet(results_file)
    print(f"  Records: {len(results):,}")

    # Check delta-neutral property: spot_pnl + perp_pnl should be ~0
    print()
    print("Checking delta-neutral property (total_spot_pnl + total_perp_pnl ≈ 0)...")

    # Calculate market exposure
    results['market_pnl'] = results['total_spot_pnl'] + results['total_perp_pnl']
    results['market_exposure_ratio'] = results['market_pnl'].abs() / results['total_funding'].abs()

    # Stats
    mean_market_pnl = results['market_pnl'].mean()
    median_market_pnl = results['market_pnl'].median()
    std_market_pnl = results['market_pnl'].std()

    print(f"  Market P&L (spot + perp):")
    print(f"    Mean: ${mean_market_pnl:,.2f}")
    print(f"    Median: ${median_market_pnl:,.2f}")
    print(f"    Std Dev: ${std_market_pnl:,.2f}")

    # Check if market P&L is small relative to funding
    avg_funding = results['total_funding'].abs().mean()
    ratio = results['market_pnl'].abs().mean() / avg_funding if avg_funding > 0 else 0

    if ratio < 0.01:  # Market exposure < 1% of funding
        print(f"  ✓ Excellent delta neutrality (market PnL is {ratio*100:.3f}% of funding)")
    elif ratio < 0.1:
        print(f"  ✓ Good delta neutrality (market PnL is {ratio*100:.1f}% of funding)")
    else:
        print(f"  ⚠ WARNING: High market exposure ({ratio*100:.1f}% of funding)")
        print(f"    This suggests imperfect hedging or timing issues")

    # Check for systematic bias
    print()
    print("Checking for systematic bias in market P&L...")
    positive_pct = (results['market_pnl'] > 0).sum() / len(results) * 100
    print(f"  Positive market P&L: {positive_pct:.1f}% of periods")

    if 45 <= positive_pct <= 55:
        print(f"  ✓ No systematic bias (near 50/50)")
    else:
        print(f"  ⚠ WARNING: Possible systematic bias")

    # Analyze correlation between funding and market PnL
    print()
    print("Checking funding-market correlation...")
    corr = results['total_funding'].corr(results['market_pnl'])
    print(f"  Correlation: {corr:.4f}")

    if abs(corr) < 0.1:
        print(f"  ✓ Low correlation (good - funding is independent of market moves)")
    else:
        print(f"  ⚠ WARNING: Significant correlation detected")
        print(f"    This could indicate look-ahead bias or timing issues")

print()
print("-" * 80)

# ============================================================================
# 4. CHECK FOR COMMON PITFALLS
# ============================================================================
print()
print("4. CHECKING FOR COMMON PITFALLS")
print("-" * 80)

if results_file.exists():
    # Check 1: Unrealistic funding rates
    print("\nCheck 1: Unrealistic funding rates")
    max_funding_rate = results['total_funding'].abs().max()
    print(f"  Max single-period funding P&L: ${max_funding_rate:,.2f}")

    # Rough check: with $1M capital, 8-hour funding should rarely exceed $10k
    if max_funding_rate > 10000:
        print(f"  ⚠ WARNING: Very high funding P&L detected")
        print(f"    This may indicate leverage calculation errors")
    else:
        print(f"  ✓ Funding P&L within reasonable range")

    # Check 2: Entry/exit timing
    print("\nCheck 2: Entry/exit timing assumptions")
    print("  Strategy assumes:")
    print("    - Entry: 1 minute after settlement (T+1m)")
    print("    - Exit: At next settlement")
    print("    - Prices: VWAP from 1-min bars")
    print("  ✓ T+1m delay helps avoid look-ahead bias")

    # Check 3: Funding rate sign
    print("\nCheck 3: Funding rate sign convention")
    positive_funding_periods = (results['total_funding'] > 0).sum()
    total_periods = len(results[results['total_funding'] != 0])
    print(f"  Profitable periods: {positive_funding_periods}/{total_periods} ({positive_funding_periods/total_periods*100:.1f}%)")

    if 20 <= positive_funding_periods/total_periods*100 <= 80:
        print(f"  ✓ Funding rates show realistic variation")
    else:
        print(f"  ⚠ WARNING: Unusual distribution of funding profitability")

    # Check 4: Artifact filtering
    print("\nCheck 4: Sub-minute artifact filtering")
    print("  ✓ Filtered 187,812 sub-minute settlement artifacts")
    print("  ✓ Only minute-aligned settlements used (00:00:00, 08:00:00, 16:00:00)")

print()
print("-" * 80)

# ============================================================================
# 5. PERFORMANCE METRICS VALIDATION
# ============================================================================
print()
print("5. PERFORMANCE METRICS VALIDATION")
print("-" * 80)

if results_file.exists():
    initial_capital = results['capital'].iloc[0] - results['period_pnl'].iloc[0]
    final_capital = results['capital'].iloc[-1]
    total_return = (final_capital - initial_capital) / initial_capital * 100

    total_funding = results['total_funding'].sum()
    total_market = results['market_pnl'].sum()

    print(f"Initial capital: ${initial_capital:,.2f}")
    print(f"Final capital: ${final_capital:,.2f}")
    print(f"Total return: {total_return:.2f}%")
    print()
    print(f"Total funding P&L: ${total_funding:,.2f}")
    print(f"Total market P&L: ${total_market:,.2f}")
    print(f"Net P&L: ${total_funding + total_market:,.2f}")

    # Verify sum
    expected_pnl = final_capital - initial_capital
    actual_pnl = total_funding + total_market
    diff = abs(expected_pnl - actual_pnl)

    if diff < 1.0:  # Allow $1 rounding error
        print(f"\n✓ P&L calculation verified (diff: ${diff:.2f})")
    else:
        print(f"\n⚠ WARNING: P&L mismatch!")
        print(f"  Expected: ${expected_pnl:,.2f}")
        print(f"  Actual: ${actual_pnl:,.2f}")
        print(f"  Difference: ${diff:,.2f}")

print()
print("="*80)
print("AUDIT COMPLETE")
print("="*80)
print()
print("KEY RECOMMENDATIONS:")
print("1. Review high market exposure periods (if any)")
print("2. Verify funding rate data source accuracy")
print("3. Cross-validate with manual calculations for sample periods")
print("4. Consider transaction costs (not yet included)")
print("5. Validate against live exchange data for recent periods")
print()
