# Time-Series Database Comparison for Quantitative Trading

## License & Open Source Status

| Database | License | Fully Open Source? | Notes |
|----------|---------|-------------------|-------|
| **DuckDB** | MIT | ✓ Yes | Fully permissive, embedded |
| **ClickHouse** | Apache 2.0 | ✓ Yes | Fully open, server-based |
| **QuestDB** | Apache 2.0 | ✓ Yes | Fully open, server-based |
| **TimescaleDB** | Apache 2.0 + Timescale License | ⚠ Hybrid | Core open source, compression/continuous aggregates require proprietary license |

## Architecture Comparison

| Database | Type | Server Required? | Best For |
|----------|------|-----------------|----------|
| **DuckDB** | Embedded OLAP | No | Single-machine analytics, embedded apps |
| **ClickHouse** | Server OLAP | Yes | Multi-billion row datasets, distributed clusters |
| **QuestDB** | Server Time-Series | Yes | High-ingestion time-series (1M+ writes/sec) |
| **TimescaleDB** | PostgreSQL Extension | Yes | PostgreSQL ecosystem, hybrid OLTP+OLAP |

## Setup Requirements

### DuckDB
```bash
pip install duckdb  # Done. No server.
```

### ClickHouse
```bash
# macOS
brew install clickhouse
clickhouse server  # Start server (port 8123/9000)

# Or Docker
docker run -d -p 8123:8123 -p 9000:9000 clickhouse/clickhouse-server
```

### QuestDB
```bash
# macOS
brew install questdb
questdb start  # Start server (port 9000, 9009)

# Or Docker
docker run -p 9000:9000 -p 9009:9009 questdb/questdb
```

### TimescaleDB
```bash
# Requires PostgreSQL 12+
brew install postgresql timescaledb

# Edit postgresql.conf
shared_preload_libraries = 'timescaledb'

# Start PostgreSQL, then:
psql -d your_db -c "CREATE EXTENSION timescaledb;"
```

## Verdict for YOUR Use Case

**Dataset**: 31,218 rows, iterative development, single machine

### ❌ NOT Recommended (Server Overhead Kills Performance)

**ClickHouse**:
- Designed for 100M+ row datasets
- Server startup: ~500ms overhead per query
- Overkill for 31K rows

**QuestDB**:
- Optimized for high-ingestion streaming (live tick data)
- Your workflow is batch processing, not streaming
- Server overhead for small datasets

**TimescaleDB**:
- PostgreSQL overhead for 31K rows is excessive
- Proprietary license for key features (compression)
- Complex setup for simple analytics

### ✓ Recommended

**DuckDB**:
- Zero server overhead (embedded)
- Designed for OLAP on small-to-medium datasets
- 2.2x faster than Parquet for your workflow
- MIT license (fully permissive)
- Perfect for single-machine quant research

## When to Use Server Databases

| Use Server DB If... | Example |
|---------------------|---------|
| Dataset > 100M rows | 10 years of tick data (billions of rows) |
| Multiple users | Team collaboration on shared data warehouse |
| Distributed data | Data sharded across multiple servers |
| Live streaming | Real-time tick ingestion from exchange feeds |
| Production trading system | 24/7 uptime, ACID guarantees for orders |

Your workflow (31K rows, single developer, iterative research) = **DuckDB is optimal**
