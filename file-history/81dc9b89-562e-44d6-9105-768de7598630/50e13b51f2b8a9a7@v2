%% Gap Detection and Filling Workflow
%% Shows the zero-gap guarantee process using authentic Binance API data
%% Reference: src/gapless_crypto_data/gap_filling/universal_gap_filler.py:597-644

flowchart TD
    %% Entry Point
    Start([CSV file or DataFrame<br/>with potential gaps]) --> DetectFormat[Detect CSV format:<br/>enhanced 11-col vs legacy 6-col]

    %% Format Detection
    DetectFormat --> CheckColumns{Has all 11<br/>enhanced cols?}
    CheckColumns -->|Yes| UseEnhanced[Format: Enhanced<br/>11-column microstructure]
    CheckColumns -->|No| CheckLegacy{Has 6<br/>legacy cols?}
    CheckLegacy -->|Yes| UseLegacy[Format: Legacy<br/>6-column OHLCV]
    CheckLegacy -->|No| FormatError[Error: Unknown format<br/>cannot process]

    %% Load and Analyze
    UseEnhanced --> LoadData[Load CSV into DataFrame]
    UseLegacy --> LoadData
    LoadData --> ParseDates[Parse 'date' column<br/>to datetime]

    ParseDates --> SortCheck{Data sorted<br/>chronologically?}
    SortCheck -->|No| SortData[Sort by timestamp]
    SortCheck -->|Yes| CalcInterval[Calculate expected interval<br/>from timeframe param]
    SortData --> CalcInterval

    %% Gap Detection
    CalcInterval --> ScanTimestamps[Scan all consecutive<br/>timestamp pairs]
    ScanTimestamps --> CalcDiffs[Calculate actual<br/>time differences]

    CalcDiffs --> CompareInterval[Compare actual vs expected<br/>for each pair]
    CompareInterval --> IdentifyGaps[Identify gaps where<br/>actual > expected + tolerance]

    IdentifyGaps --> HasGaps{Any gaps<br/>detected?}
    HasGaps -->|No| NoContinuous[Data is continuous!<br/>No filling needed]
    HasGaps -->|Yes| CountGaps[Count total gaps<br/>and affected periods]

    %% Gap Details
    CountGaps --> LogGapInfo[Log gap details:<br/>start time, end time,<br/>expected bars, missing bars]

    LogGapInfo --> PrioritizeGaps[Prioritize gaps<br/>by size and criticality]

    %% Filling Process Start
    PrioritizeGaps --> ForEachGap{For each gap}
    ForEachGap --> CalcGapRange[Calculate exact<br/>time range to fill]

    CalcGapRange --> BuildAPIRequest[Build Binance API request:<br/>symbol, timeframe,<br/>startTime, endTime, limit]

    %% API Call
    BuildAPIRequest --> CallBinanceAPI[Call Binance REST API<br/>klines endpoint]
    CallBinanceAPI --> CheckAPIResponse{API<br/>response?}

    CheckAPIResponse -->|200 OK + data| ParseAPI[Parse API response<br/>array of klines]
    CheckAPIResponse -->|200 OK + empty| LogNoData[Log: No data available<br/>from Binance for period]
    CheckAPIResponse -->|Error| LogAPIError[Log API error<br/>skip this gap]

    %% Process API Data
    ParseAPI --> ConvertFormat[Convert API format<br/>to CSV format]
    ConvertFormat --> FilterToGap[Filter data to exact<br/>gap period only]

    FilterToGap --> ValidateAPI[Validate API data:<br/>timestamps, OHLCV logic]
    ValidateAPI --> MatchFormat{Match CSV<br/>format?}

    MatchFormat -->|Enhanced| ExtractAll11[Extract all 11 columns]
    MatchFormat -->|Legacy| ExtractOHLCV6[Extract 6 OHLCV columns]

    %% Merge Process
    ExtractAll11 --> MergeData[Merge existing + new data]
    ExtractOHLCV6 --> MergeData

    MergeData --> Deduplicate[Deduplicate by timestamp<br/>prefer existing data]
    Deduplicate --> ReSort[Sort by timestamp again]

    %% Validation
    ReSort --> ValidateMerge[Validate merge:<br/>no new gaps created?]
    ValidateMerge --> VerifyFill{Gap successfully<br/>filled?}

    VerifyFill -->|Yes| RecordSuccess[Record success<br/>increment filled_count]
    VerifyFill -->|No| RecordPartial[Record partial fill<br/>or failure]

    RecordSuccess --> MoreGaps{More gaps<br/>to fill?}
    RecordPartial --> MoreGaps
    LogNoData --> MoreGaps
    LogAPIError --> MoreGaps

    MoreGaps -->|Yes| ForEachGap
    MoreGaps -->|No| FinalValidation[Final validation:<br/>scan for remaining gaps]

    %% Final Steps
    FinalValidation --> CalcStats[Calculate statistics:<br/>gaps_detected, gaps_filled,<br/>success_rate, data_quality]

    CalcStats --> UpdateMetadata[Update metadata JSON:<br/>gap_analysis section]
    UpdateMetadata --> SaveResults{Save to<br/>original file?}

    SaveResults -->|Yes| AtomicSave[Atomic save operation:<br/>write to temp â†’ rename]
    SaveResults -->|No| ReturnDF[Return filled DataFrame<br/>without saving]

    AtomicSave --> BackupOriginal[Backup original file<br/>.bak extension]
    BackupOriginal --> WriteNew[Write new filled data]
    WriteNew --> VerifyWrite{Write<br/>successful?}

    VerifyWrite -->|Yes| DeleteBackup[Delete backup<br/>all good!]
    VerifyWrite -->|No| RestoreBackup[Restore from backup<br/>log error]

    DeleteBackup --> Complete([Gap filling complete!<br/>Zero gaps achieved])
    RestoreBackup --> ErrorEnd([End with error])
    ReturnDF --> Complete
    NoContinuous --> Complete
    FormatError -.-> ErrorEnd

    %% Styling
    classDef apiNode fill:#fff3cd,stroke:#856404,stroke-width:2px
    classDef successNode fill:#d4edda,stroke:#155724,stroke-width:2px
    classDef errorNode fill:#f8d7da,stroke:#721c24,stroke-width:2px
    classDef criticalNode fill:#cfe2ff,stroke:#084298,stroke-width:3px
    classDef decisionNode fill:#e7f3ff,stroke:#004085,stroke-width:2px
    classDef dataNode fill:#f8f9fa,stroke:#6c757d,stroke-width:1px

    class BuildAPIRequest,CallBinanceAPI,CheckAPIResponse,ParseAPI apiNode
    class RecordSuccess,Complete,DeleteBackup,NoContinuous successNode
    class FormatError,LogAPIError,ErrorEnd,RestoreBackup errorNode
    class Start,HasGaps,MergeData,ValidateMerge,Complete criticalNode
    class CheckColumns,CheckLegacy,SortCheck,HasGaps,MatchFormat,VerifyFill,SaveResults,VerifyWrite decisionNode
    class LoadData,ParseDates,ScanTimestamps,CalcDiffs,ConvertFormat dataNode
