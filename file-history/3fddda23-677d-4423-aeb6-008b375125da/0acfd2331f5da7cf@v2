# Phase 5 Implementation TODO

**Status**: Partial - Core scripts created, IPSS and execution remaining
**Date**: 2025-10-03

## Completed ✅

1. **Comprehensive README.md** - Full Phase 5 specification with SLOs
2. **compute_targets.py** - MAE/MFE quality labeling implementation
3. **apply_pruning_manifest.py** - 89 → 48 feature filtering
4. **run_vif_filter.py** - 48 → 37 VIF filtering (validated 9.7s)
5. **Results directory** - Created structure

## Remaining TODO

### 1. Create EmbargoedTimeSeriesSplit Class
**File**: `ml_feature_set/validation/time_series_cv.py`

**Implementation** (from README.md lines 149-186):
```python
import numpy as np
from sklearn.model_selection import BaseCrossValidator

class EmbargoedTimeSeriesSplit(BaseCrossValidator):
    """
    Time series CV with embargo period

    Embargo prevents target lookahead:
    Train: [0...1000]
    Gap: [1001...1020]  (H=20 bars embargo)
    Val: [1021...2000]
    """

    def __init__(self, n_splits=5, test_size=0.2, embargo=20):
        self.n_splits = n_splits
        self.test_size = test_size
        self.embargo = embargo

    def split(self, X, y=None, groups=None):
        n = len(X)
        test_size = int(n * self.test_size)

        for i in range(self.n_splits):
            test_end = n - (self.n_splits - i - 1) * test_size
            test_start = test_end - test_size
            train_end = test_start - self.embargo

            if train_end <= 0:
                raise ValueError(
                    f"Insufficient data for {self.n_splits} splits "
                    f"with embargo={self.embargo}"
                )

            train_idx = np.arange(0, train_end)
            test_idx = np.arange(test_start, test_end)

            yield train_idx, test_idx

    def get_n_splits(self, X=None, y=None, groups=None):
        return self.n_splits
```

**Also create**: `ml_feature_set/validation/__init__.py` (empty file)

---

### 2. Implement run_ipss.py (IPSS Stability Selection)
**File**: `experiments/phase5_mae_mfe_ipss_20251003/run_ipss.py`

**Simplified implementation** (full version in README.md lines 192-282):

```python
"""
IPSS Stability Selection: 37 → 20-30 Features

Note: Multi-output regression [long_quality, short_quality]
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from sklearn.ensemble import RandomForestRegressor
from sklearn.inspection import permutation_importance
from ml_feature_set.validation.time_series_cv import EmbargoedTimeSeriesSplit


def ipss_simple(X, y, n_bootstrap=100, threshold=0.70, embargo=20):
    """
    Simplified IPSS (no arch bootstrap for now - use sklearn only)

    Args:
        X: Features (37 features after VIF)
        y: Targets (n_samples, 2) for [long_quality, short_quality]
        n_bootstrap: Number of bootstrap iterations
        threshold: Selection frequency cutoff
        embargo: Embargo bars

    Returns:
        selected_features, selection_freq
    """
    cv = EmbargoedTimeSeriesSplit(n_splits=5, embargo=embargo)

    selection_counts = np.zeros(X.shape[1])
    total = 0

    for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X)):
        print(f"  CV Fold {fold_idx+1}/5...")

        X_train = X.iloc[train_idx]
        y_train = y[train_idx]
        X_val = X.iloc[val_idx]
        y_val = y[val_idx]

        # Train model (multi-output regression)
        model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
        model.fit(X_train, y_train)

        # Permutation importance
        result = permutation_importance(
            model, X_val, y_val,
            n_repeats=10,
            random_state=42,
            n_jobs=-1
        )

        # Count selections (importance > 0)
        selected = result.importances_mean > 0
        selection_counts += selected
        total += 1

    # Calculate frequency
    selection_freq = selection_counts / total
    selected_mask = selection_freq >= threshold
    selected_features = X.columns[selected_mask].tolist()

    freq_dict = dict(zip(X.columns, selection_freq))

    return selected_features, freq_dict


def main():
    print("="*70)
    print("Phase 5: IPSS Stability Selection (37 → 20-30 Features)")
    print("="*70)

    # Load VIF-filtered features
    atoms_csv = Path(__file__).parent / "results/atoms_37_vif.csv"
    quality_csv = Path(__file__).parent / "results/quality_labels.csv"

    print(f"\nLoading features from: {atoms_csv}")
    X = pd.read_csv(atoms_csv, index_col=0, parse_dates=True)

    print(f"Loading quality labels from: {quality_csv}")
    quality_df = pd.read_csv(quality_csv, index_col=0, parse_dates=True)

    # Align indices and drop NaN
    common_idx = X.index.intersection(quality_df.index)
    X = X.loc[common_idx]
    quality_df = quality_df.loc[common_idx]

    # Create multi-output target
    y = quality_df[['long_quality', 'short_quality']].values

    # Drop rows with NaN in y
    valid_mask = ~np.isnan(y).any(axis=1)
    X = X[valid_mask]
    y = y[valid_mask]

    print(f"\nDataset after alignment:")
    print(f"  Features: {X.shape[1]}")
    print(f"  Samples: {X.shape[0]}")

    # Run IPSS
    print(f"\nRunning IPSS (threshold=0.70, 5-fold CV)...")
    selected_features, selection_freq = ipss_simple(
        X, y,
        n_bootstrap=1,  # Simplified: just CV, no bootstrap
        threshold=0.70,
        embargo=20
    )

    print(f"\nIPSS complete:")
    print(f"  Selected features: {len(selected_features)}")

    # Save results
    output_txt = Path(__file__).parent / "results/features_final_ipss.txt"
    with open(output_txt, 'w') as f:
        for feat in selected_features:
            f.write(f"{feat}\n")

    print(f"\n✓ Final feature list saved to: {output_txt}")

    # Save selection frequencies
    freq_df = pd.DataFrame([
        {'feature': feat, 'selection_freq': freq}
        for feat, freq in sorted(selection_freq.items(), key=lambda x: -x[1])
    ])
    freq_csv = Path(__file__).parent / "results/ipss_selection_freq.csv"
    freq_df.to_csv(freq_csv, index=False)

    print(f"✓ Selection frequencies saved to: {freq_csv}")

    print("\n" + "="*70)
    print("IPSS complete")
    print("="*70)


if __name__ == '__main__':
    main()
```

**Note**: Simplified to use CV only (no arch bootstrap). Add bootstrap later if needed.

---

### 3. Execute Phase 5 Pipeline

**Run in sequence** (Docker):

```bash
cd /workspace/experiments/phase5_mae_mfe_ipss_20251003

# Stage 1: Targets
docker exec ml-dev python -m experiments.phase5_mae_mfe_ipss_20251003.compute_targets

# Stage 2: Pruning manifest
docker exec ml-dev python -m experiments.phase5_mae_mfe_ipss_20251003.apply_pruning_manifest

# Stage 3: VIF filtering
docker exec ml-dev python -m experiments.phase5_mae_mfe_ipss_20251003.run_vif_filter

# Stage 4: IPSS
docker exec ml-dev python -m experiments.phase5_mae_mfe_ipss_20251003.run_ipss
```

**Expected output**:
- `results/quality_labels.csv` - MAE/MFE labels
- `results/features_48_pruned.txt` - After pruning manifest
- `results/features_37_vif.txt` - After VIF
- `results/features_final_ipss.txt` - Final 20-30 features

---

### 4. Generate FINDINGS.md

**Create** `experiments/phase5_mae_mfe_ipss_20251003/generate_report.py`:

```python
"""
Generate Phase 5 Summary Report
"""

import pandas as pd
from pathlib import Path

def main():
    results_dir = Path(__file__).parent / "results"

    # Load all artifacts
    quality_df = pd.read_csv(results_dir / "quality_labels.csv", index_col=0)
    vif_log = pd.read_csv(results_dir / "vif_removal_log.csv")
    ipss_freq = pd.read_csv(results_dir / "ipss_selection_freq.csv")

    with open(results_dir / "features_final_ipss.txt") as f:
        final_features = [line.strip() for line in f]

    # Generate FINDINGS.md
    findings_md = Path(__file__).parent / "FINDINGS.md"
    with open(findings_md, 'w') as f:
        f.write("# Phase 5: MAE/MFE IPSS Feature Selection - Findings\n\n")
        f.write(f"**Date**: 2025-10-03\n")
        f.write(f"**Status**: Complete\n\n")

        f.write("## Pipeline Summary\n\n")
        f.write(f"- 89 atoms → 48 features (pruning manifest)\n")
        f.write(f"- 48 features → 37 features (VIF ≤ 5.0)\n")
        f.write(f"- 37 features → {len(final_features)} features (IPSS ≥ 0.70)\n\n")

        f.write("## Target Variable Distribution\n\n")
        f.write(f"Quality label statistics:\n")
        f.write(f"- Total samples: {len(quality_df)}\n")
        f.write(f"- Valid quality: {quality_df['best_quality'].notna().sum()}\n")
        f.write(f"- Quality mean: {quality_df['best_quality'].mean():.3f}\n")
        f.write(f"- Quality median: {quality_df['best_quality'].median():.3f}\n\n")

        f.write("## VIF Filtering\n\n")
        f.write(f"Removed {len(vif_log)} features:\n\n")
        for _, row in vif_log.iterrows():
            f.write(f"- {row['feature']} (VIF={row['vif']:.2f})\n")
        f.write("\n")

        f.write("## Final Selected Features\n\n")
        for feat in final_features:
            freq = ipss_freq[ipss_freq['feature']==feat]['selection_freq'].values[0]
            f.write(f"- {feat} (freq={freq:.3f})\n")
        f.write("\n")

        f.write("## Next: Phase 6 OOD Robustness Testing\n\n")
        f.write("Requires multi-year data (2022-2025)\n")

    print(f"✓ FINDINGS.md generated: {findings_md}")

if __name__ == '__main__':
    main()
```

**Run**:
```bash
docker exec ml-dev python -m experiments.phase5_mae_mfe_ipss_20251003.generate_report
```

---

## Commit Workflow

After execution complete:

```bash
git add experiments/phase5_mae_mfe_ipss_20251003/
git add ml_feature_set/validation/time_series_cv.py
git commit -m "feat(phase5): MAE/MFE quality-based feature selection with IPSS

Phase 5 Implementation:
- MAE/MFE quality target (reward/risk ratio, H=20 bars)
- Pruning manifest application (89 → 48 features)
- VIF filtering (48 → 37, threshold ≤ 5.0, 9.7s)
- IPSS stability selection (37 → 20-30, threshold ≥ 0.70)
- Embargoed time series CV (embargo=20 bars)

SLOs: Out-of-box implementations, error propagation, observability
Target: Directional CTA trading (high-frequency intraday)
Result: 20-30 validated features for Phase 6

Context: EL-1009 OOD robustness pipeline"

git push
```

---

## Current Status

**Implemented**:
- ✅ README.md (comprehensive specification)
- ✅ compute_targets.py
- ✅ apply_pruning_manifest.py
- ✅ run_vif_filter.py

**Remaining** (outlined above):
- ⏳ EmbargoedTimeSeriesSplit class
- ⏳ run_ipss.py
- ⏳ generate_report.py
- ⏳ Pipeline execution
- ⏳ FINDINGS.md

**Estimated time**: 2-3 hours to complete remaining work
