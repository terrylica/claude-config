# OOD-Robust ML for Range Bar Prediction

End-to-end machine learning pipeline for **Out-of-Distribution robust** cryptocurrency range bar prediction with **automatic feature generation**.

## Overview

This research pipeline addresses the challenge of building ML models that remain reliable when market conditions shift unexpectedly (distribution shifts, volatility regime changes, crisis events).

### Key Features

- **Transformer-based Auto-Features**: Zero human bias in feature engineering
- **Dual-Task Learning**: Direction prediction + anomaly detection
- **Regime-Stratified Training**: Prevents overfitting to dominant market conditions
- **Conformal Prediction**: Distribution-free uncertainty quantification
- **Stress Testing**: Validates robustness on historical crises (Terra/Luna, FTX)

## Architecture

```
CSV Files (175K bars, 3.75 years)
    ↓
Data Pipeline (regime detection, stratified splits)
    ↓
Transformer Encoder (14 features → 128-dim embeddings)
    ↓
Dual-Task Head (direction classifier + anomaly detector)
    ↓
Conformal Calibration (uncertainty quantification)
    ↓
OOD Evaluation + Stress Testing
```

See [ARCHITECTURE.md](ARCHITECTURE.md) for detailed design decisions.

## Quick Start

### Installation

```bash
# Install dependencies
cd research/ml_ood
uv sync

# Or manually install
uv pip install -e .
```

### Training

```bash
# Basic training (default: SOLUSDT 0.50bps)
uv run --active python -m research.ml_ood.train \
    --data output/solusdt_historical_2022_2025/spot_SOLUSDT_rangebar_20220101_20250930_0050bps.csv \
    --epochs 50 \
    --batch-size 256 \
    --device auto

# With custom parameters
uv run --active python -m research.ml_ood.train \
    --data <path-to-csv> \
    --epochs 100 \
    --sequence-len 128 \
    --embedding-dim 256 \
    --lr 5e-5 \
    --output-dir experiments/run1
```

### Evaluation

```python
# Example evaluation script
from pathlib import Path
import torch
from research.ml_ood.models import OODRobustRangeBarModel
from research.ml_ood.data import RangeBarDataset
from research.ml_ood.evaluation import StressTestSuite, OODMetrics
from research.ml_ood.training import ConformalCalibrator

# Load model
checkpoint = torch.load("experiments/final_model.pt")
model = OODRobustRangeBarModel()
model.load_state_dict(checkpoint["model_state_dict"])
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Load dataset
dataset = RangeBarDataset(
    csv_path=Path("output/solusdt_historical_2022_2025/spot_SOLUSDT_rangebar_20220101_20250930_0050bps.csv"),
    sequence_len=64,
)

# Stress testing
stress_tester = StressTestSuite(model, dataset, device)
terra_luna_metrics = stress_tester.run_stress_test("terra_luna_crash")
ftx_metrics = stress_tester.run_stress_test("ftx_collapse")

# Conformal prediction
calibrator = ConformalCalibrator(alpha=0.1)
calibrator.calibrate(model, calibration_loader, device)
coverage_metrics = calibrator.evaluate_coverage(model, test_loader, device)

# OOD metrics
metrics = OODMetrics.compute_all_metrics(model, test_loader, device)
OODMetrics.print_metrics(metrics, title="Test Set Evaluation")
```

## Project Structure

```
research/ml_ood/
├── README.md                    # This file
├── ARCHITECTURE.md              # Detailed architecture decisions
├── pyproject.toml               # Dependencies
│
├── data/                        # Data loading
│   ├── dataset.py              # PyTorch dataset
│   ├── regime.py               # Market regime detection
│   └── utils.py                # CSV parsing, splits
│
├── models/                      # Neural network models
│   ├── encoder.py              # Transformer encoder
│   ├── heads.py                # Direction + anomaly heads
│   └── ood_model.py            # Complete OOD model
│
├── training/                    # Training infrastructure
│   ├── sampler.py              # Regime-stratified sampler
│   ├── conformal.py            # Conformal calibration
│   └── trainer.py              # Training loop
│
├── evaluation/                  # Evaluation tools
│   ├── stress_test.py          # Crisis period testing
│   └── metrics.py              # OOD metrics
│
└── train.py                     # Main training script
```

## Design Decisions (from Clarification)

### Prediction Target
- **Primary**: Direction classification (up/down/sideways)
- **Secondary**: Anomaly detection (OOD identification)

### OOD Definition
**Priority**: Temporal shift + Volatility regime shift
- Train on 2022-2023, test on 2024-2025
- Stratified by volatility quintiles

### Auto-Feature Generation
**Approach**: Transformer-based end-to-end learning
- 14 input features (OHLCV + derived)
- Self-attention discovers temporal patterns
- No hand-crafted technical indicators

### Validation Strategy
1. **Regime-stratified splits**: Balanced representation across volatility regimes
2. **Conformal prediction**: 90% coverage guarantees on OOD data
3. **Stress testing**: 2022 Terra/Luna crash, 2023 FTX collapse

## Data Splits

### Temporal
- **Train**: 2022-01-01 to 2023-12-31 (2 years, ~95K bars)
- **Val**: 2024-01-01 to 2024-06-30 (6 months, ~24K bars)
- **Test**: 2024-07-01 to 2025-09-30 (15 months, ~57K bars)

### Stress Periods (Held-Out)
- **Terra/Luna Crash**: 2022-05-07 to 2022-05-12 (SOL: $90 → $40)
- **FTX Collapse**: 2022-11-06 to 2022-11-11 (SOL: $35 → $13)

## Model Architecture

### Transformer Encoder
- **Input**: (batch, 64, 14) sequences
- **Layers**: 4 transformer layers
- **Attention**: 8 heads, 256-dim hidden
- **Output**: (batch, 128) embeddings

### Dual-Task Head
1. **Direction Classifier**
   - 3 classes: up/down/sideways (±0.2% threshold)
   - Cross-entropy loss with label smoothing

2. **Anomaly Detector**
   - Reconstruction-based autoencoder
   - High error → OOD sample

### OOD Robustness Mechanisms
- Layer normalization (distribution shift tolerance)
- Dropout (MC Dropout for uncertainty)
- Regime-stratified sampling (prevents overfitting)
- Conformal calibration (valid uncertainty intervals)

## Experiment Tracking

### TensorBoard

```bash
# Launch TensorBoard
tensorboard --logdir research/ml_ood/experiments/logs

# Metrics logged:
# - train/batch_loss, train/direction_loss, train/anomaly_loss
# - train/epoch_loss, train/lr
# - Attention weight visualizations (future)
```

### Checkpoints

Saved every 5 epochs to `experiments/checkpoint_epoch{N}.pt`:
- Model state dict
- Optimizer state
- Training metrics
- Normalization statistics

## Evaluation Metrics

### OOD-Specific
- **Regime-conditional accuracy**: Performance per volatility quintile
- **Expected Calibration Error (ECE)**: Calibration quality
- **Conformal coverage**: Empirical vs target coverage (90%)
- **Stress period degradation**: Performance drop during crises

### Standard
- Accuracy, precision, recall, F1
- Per-class accuracy (up/down/sideways)
- Confusion matrix
- Anomaly score distribution

## Known Limitations & Future Work

### Current Limitations
1. Single-asset evaluation (SOLUSDT only)
2. Fixed sequence length (64 bars)
3. No test-time adaptation
4. Attention weights not yet visualized

### Future Enhancements
1. **Cross-asset validation**: Train on SOL, test on BTC/ETH
2. **Test-time adaptation**: Update model on recent data
3. **Ensemble methods**: Multiple models for better uncertainty
4. **Attention visualization**: Interpret learned patterns
5. **Production optimization**: Model distillation for sub-ms inference

## References

### OOD Robustness
- Arjovsky et al. (2019): Invariant Risk Minimization
- Vovk et al. (2005): Algorithmic Learning in a Random World
- Angelopoulos & Bates (2022): Gentle Introduction to Conformal Prediction

### Transformers for Time Series
- Lim et al. (2021): Temporal Fusion Transformer
- Zhou et al. (2021): Informer: Beyond Efficient Transformer

### Crypto-Specific
- Range bars: Time-invariant sampling for non-stationary data
- Regime-conditional models for volatile assets

## License

Part of the `rangebar` project - see main repository LICENSE.

## Contact

For questions or issues, open a GitHub issue on the main `rangebar` repository.
