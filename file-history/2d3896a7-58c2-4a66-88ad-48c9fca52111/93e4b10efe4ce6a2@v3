# Preflight Checklist for EvolutionaryForest

**Purpose**: Run these checks BEFORE feeding data to EvolutionaryForest to avoid silent bugs (especially data leakage).

---

## ‚ö†Ô∏è 8-Point Checklist

### 1. ‚úÖ Non-Anticipative Verification (No Future Peeking)
```python
# ‚úÖ VERIFY: All temporal features use .shift() with POSITIVE lags
# ‚ùå WRONG: df['future_price'] = df['close'].shift(-1)  # FUTURE PEEKING!
# ‚úÖ CORRECT: df['past_price'] = df['close'].shift(1)   # Non-anticipative

# Quick audit:
for col in df.columns:
    if 'lag' in col.lower():
        print(f"Verify {col} uses .shift(positive_number)")
```

### 2. ‚úÖ NaN/Inf Check (Rolling Windows Create NaN)
```python
# Check for NaN (created by rolling windows at start)
print(f"NaN count per column:\n{df.isna().sum()}")

# Check for inf values (division by zero in feature engineering)
print(f"Inf count per column:\n{np.isinf(df.select_dtypes(include=[np.number])).sum()}")

# ‚úÖ MUST DO: Drop NaN rows
df = df.dropna()

# ‚úÖ MUST DO: Replace inf with large number or drop
df = df.replace([np.inf, -np.inf], np.nan).dropna()

print(f"Clean data shape: {df.shape}")
```

### 3. ‚úÖ Temporal Order Verification
```python
# ‚úÖ VERIFY: Data is sorted by date (ascending)
assert df.index.is_monotonic_increasing, "‚ùå Data not in temporal order!"

# ‚úÖ VERIFY: No duplicate timestamps
assert not df.index.duplicated().any(), "‚ùå Duplicate timestamps found!"

print("‚úÖ Temporal order verified")
```

### 4. ‚úÖ Train/Test Split (TEMPORAL, Not Random!)
```python
# ‚ùå WRONG: Random split destroys temporal structure
# train, test = train_test_split(df, test_size=0.2, random_state=42)  # NO!

# ‚úÖ CORRECT: Temporal split
split_idx = int(len(df) * 0.8)
train = df.iloc[:split_idx]   # Earlier data
test = df.iloc[split_idx:]     # Future data (OOD)

print(f"Train period: {train.index[0]} to {train.index[-1]}")
print(f"Test period: {test.index[0]} to {test.index[-1]}")

# ‚úÖ VERIFY: No temporal overlap
assert train.index[-1] < test.index[0], "‚ùå Train/test temporal overlap!"
```

### 5. ‚úÖ Target Variable Verification
```python
# ‚úÖ VERIFY: Target is k-step AHEAD (future returns)
# Should use NEGATIVE shift to look forward
assert 'target_' in df.columns.tolist(), "‚ùå No target variable!"

# Check target was created correctly:
# Example: df['target_5step'] = (df['close'].shift(-5) / df['close'] - 1)
print(f"Target columns: {[c for c in df.columns if 'target' in c]}")

# ‚úÖ VERIFY: Target not in feature columns
feature_cols = [col for col in df.columns if col.startswith(('close_', 'volume_', 'return_'))]
assert not any('target' in c for c in feature_cols), "‚ùå Target leaked into features!"
```

### 6. ‚úÖ Feature Column Selection
```python
# ‚úÖ VERIFY: Only temporal features selected (no raw target, no metadata)
feature_cols = [col for col in df.columns if col.startswith(('close_', 'volume_', 'return_', 'rsi', 'atr'))]

print(f"Selected {len(feature_cols)} features:")
print(feature_cols[:10], "...")

# ‚úÖ VERIFY: No constant features (zero variance)
X = df[feature_cols].values
zero_var_cols = [feature_cols[i] for i in range(X.shape[1]) if np.var(X[:, i]) == 0]
if zero_var_cols:
    print(f"‚ö†Ô∏è  Removing zero-variance features: {zero_var_cols}")
    feature_cols = [c for c in feature_cols if c not in zero_var_cols]
```

### 7. ‚úÖ Memory Check (Large Datasets)
```python
# ‚úÖ CHECK: Dataset size vs available RAM
n_samples, n_features = df[feature_cols].shape
memory_mb = (n_samples * n_features * 8) / (1024**2)  # 8 bytes per float64

print(f"Dataset: {n_samples:,} samples √ó {n_features} features")
print(f"Estimated memory: {memory_mb:.1f} MB")

# ‚úÖ RECOMMENDATION: Subsample if >500K samples for initial testing
if n_samples > 500_000:
    print(f"‚ö†Ô∏è  Large dataset! Consider subsampling for initial experiments:")
    print(f"   df_sample = df.iloc[::10]  # Every 10th row")
```

### 8. ‚úÖ Sanity Check: Feature Statistics
```python
# ‚úÖ VERIFY: Feature distributions are reasonable
X = df[feature_cols].values

print("\nFeature statistics:")
print(f"  Mean range: [{X.mean(axis=0).min():.2e}, {X.mean(axis=0).max():.2e}]")
print(f"  Std range:  [{X.std(axis=0).min():.2e}, {X.std(axis=0).max():.2e}]")
print(f"  Min value:  {X.min():.2e}")
print(f"  Max value:  {X.max():.2e}")

# ‚úÖ WARNING: Extreme values might indicate bugs
if abs(X.max()) > 1e6 or abs(X.min()) > 1e6:
    print("‚ö†Ô∏è  Extreme values detected! Check feature engineering code.")
```

---

## ‚úÖ Complete Preflight Function

```python
def preflight_check(df, feature_cols, target_col='target_5step'):
    """Run all preflight checks before EvolutionaryForest."""

    print("="*70)
    print("PREFLIGHT CHECKLIST")
    print("="*70)

    # 1. NaN check
    nan_count = df.isna().sum().sum()
    assert nan_count == 0, f"‚ùå Found {nan_count} NaN values! Run df.dropna()"
    print("‚úÖ No NaN values")

    # 2. Inf check
    inf_count = np.isinf(df[feature_cols].values).sum()
    assert inf_count == 0, f"‚ùå Found {inf_count} Inf values!"
    print("‚úÖ No Inf values")

    # 3. Temporal order
    assert df.index.is_monotonic_increasing, "‚ùå Not in temporal order!"
    print("‚úÖ Temporal order verified")

    # 4. No duplicates
    assert not df.index.duplicated().any(), "‚ùå Duplicate timestamps!"
    print("‚úÖ No duplicate timestamps")

    # 5. Target not in features
    assert target_col not in feature_cols, "‚ùå Target in features!"
    print("‚úÖ Target not leaked into features")

    # 6. Zero variance check
    X = df[feature_cols].values
    zero_var = (X.std(axis=0) == 0).sum()
    assert zero_var == 0, f"‚ùå Found {zero_var} zero-variance features!"
    print("‚úÖ No zero-variance features")

    # 7. Size check
    n_samples, n_features = X.shape
    print(f"‚úÖ Dataset: {n_samples:,} samples √ó {n_features} features")

    print("="*70)
    print("üöÄ PREFLIGHT COMPLETE - READY FOR EVOLUTIONARY FOREST")
    print("="*70)

    return True

# Usage:
preflight_check(df, feature_cols)
```

---

## Why Each Check Matters

| Check | Risk Without It | Impact |
|-------|----------------|---------|
| **Non-anticipative** | Future peeking | Fake performance, production failure |
| **NaN/Inf** | Silent crashes | Bad features, numerical instability |
| **Temporal order** | Data leakage | Shuffled time series |
| **Temporal split** | Data leakage | No true OOD validation |
| **Target verification** | Target leakage | Perfect R¬≤ but useless in production |
| **Feature selection** | Zero variance | Numerical issues, crashes |
| **Memory check** | OOM crashes | Wasted compute time |
| **Statistics check** | Feature bugs | Extreme values indicate errors |

---

## Integration with Workflow

```
1. Load Binance CSV
2. Create temporal features (lags, rolling)
3. ‚ö†Ô∏è  RUN PREFLIGHT_CHECK() ‚Üê THIS FILE
4. EvolutionaryForest (non-linear combinations)
5. Validate OOD generalization
6. Export to seq-to-seq model
```

---

**Last Updated**: 2025-10-05
