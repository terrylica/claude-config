openapi: 3.1.0
info:
  title: Feature Redundancy Analysis Specification
  description: Machine-readable redundancy detection for 121 ATR-Adaptive Laguerre RSI features
  version: 1.2.0
  x-changelog:
    - version: 1.2.0
      date: 2025-10-07
      changes:
        - "DISCOVERY: Constant features cause NaN in correlation matrix"
        - "Found 2 constant columns: all_intervals_crossed_overbought, cascade_crossing_down"
        - "Solution: Drop zero-variance columns before correlation computation"
        - "Result: 119 features analyzed, 42 features flagged for DROP, 79 features remaining"
        - "Redundancy findings: 686 total pairs (220 DROP pairs, 466 REVIEW pairs)"
    - version: 1.1.0
      date: 2025-10-07
      changes:
        - "DISCOVERY: Feature redundancy structure is symbol-independent"
        - "Use single-symbol features for analysis (avoids NaN in correlation matrix)"
        - "Rationale: Combining features from multiple symbols with ignore_index=True causes timestamp misalignment"
        - "Solution: Analyze features from BTCUSDT only (structure generalizes to all symbols)"
    - version: 1.0.0
      date: 2025-10-07
      changes:
        - Initial specification based on LGTM approval
        - Spearman correlation edge list as primary output
        - Hierarchical clustering with fcluster for flat assignments
        - Decision table CSV for actionable redundancy removal
        - IC validation framework integration
        - Parameterized screening workflow for iterative refinement

components:
  schemas:
    AnalysisConfiguration:
      type: object
      description: Configuration for redundancy analysis run
      properties:
        data_specification:
          type: object
          properties:
            symbols:
              type: array
              items:
                type: string
              example: ["BTCUSDT", "ETHUSDT", "SOLUSDT"]
            base_interval:
              type: string
              example: "2h"
            date_range:
              type: object
              properties:
                end_date:
                  type: string
                  example: "2025-09-30"
                duration_years:
                  type: integer
                  example: 3
            data_source:
              type: string
              example: "gapless-crypto-data"

        feature_config:
          type: object
          properties:
            mode:
              type: string
              enum: ["single-interval", "multi-interval"]
              example: "multi-interval"
            multiplier_1:
              type: integer
              example: 4
              description: "4x base interval (2h * 4 = 8h)"
            multiplier_2:
              type: integer
              example: 12
              description: "12x base interval (2h * 12 = 24h)"
            expected_feature_count:
              type: integer
              example: 121
              description: "27 single-interval × 3 timeframes + 40 cross-interval"

        redundancy_thresholds:
          type: object
          properties:
            high_redundancy:
              type: number
              example: 0.9
              description: "Auto-drop features with |ρ| > 0.9"
            medium_redundancy:
              type: number
              example: 0.7
              description: "Flag for review features with 0.7 < |ρ| ≤ 0.9"
            cluster_distance_threshold:
              type: number
              example: 0.3
              description: "Dendrogram cut height (1 - threshold = 0.7 correlation)"

        correlation_method:
          type: string
          enum: ["spearman", "pearson"]
          example: "spearman"
          description: "Spearman handles non-linear RSI transformations"

        clustering_method:
          type: string
          enum: ["ward", "average", "complete", "single"]
          example: "ward"
          description: "Ward linkage for hierarchical clustering"

    OutputFiles:
      type: object
      description: Machine-readable output files generated by analysis
      properties:
        edge_list:
          type: object
          properties:
            path:
              type: string
              example: "/tmp/feature_correlations_edgelist.csv"
            format:
              type: string
              example: "CSV"
            columns:
              type: array
              items:
                type: string
              example: ["feature_1", "feature_2", "correlation"]
            description:
              type: string
              example: "Pairwise Spearman correlations as edge list, filtered by threshold"
            usage:
              type: string
              example: "awk '$3 > 0.9' /tmp/feature_correlations_edgelist.csv"

        cluster_assignments:
          type: object
          properties:
            path:
              type: string
              example: "/tmp/feature_clusters.csv"
            format:
              type: string
              example: "CSV"
            columns:
              type: array
              items:
                type: string
              example: ["feature", "cluster_id"]
            description:
              type: string
              example: "Flat cluster assignments from hierarchical clustering (fcluster)"
            usage:
              type: string
              example: "awk '$2 == 1' /tmp/feature_clusters.csv"

        redundancy_decisions:
          type: object
          properties:
            path:
              type: string
              example: "/tmp/redundancy_decisions.csv"
            format:
              type: string
              example: "CSV"
            columns:
              type: array
              items:
                type: string
              example: ["feature_1", "feature_2", "correlation", "action", "drop_feature", "keep_feature", "reason"]
            description:
              type: string
              example: "Actionable decisions for each redundant pair (DROP/REVIEW/KEEP)"
            usage:
              type: string
              example: "grep DROP /tmp/redundancy_decisions.csv | cut -d, -f5"

        graph_metrics:
          type: object
          properties:
            path:
              type: string
              example: "/tmp/graph_metrics.json"
            format:
              type: string
              example: "JSON"
            schema:
              type: object
              properties:
                connected_components:
                  type: array
                  description: "Feature families (strongly connected)"
                degree_centrality:
                  type: object
                  description: "Hub features (correlated with many others)"
                clustering_coefficient:
                  type: object
                  description: "Feature neighborhood density"
            usage:
              type: string
              example: "jq '.degree_centrality | to_entries | sort_by(.value) | reverse' /tmp/graph_metrics.json"

        ic_validation:
          type: object
          properties:
            path:
              type: string
              example: "/tmp/ic_validation_redundancy_removal.csv"
            format:
              type: string
              example: "CSV"
            columns:
              type: array
              items:
                type: string
              example: ["metric", "value"]
            description:
              type: string
              example: "IC comparison before/after redundancy removal"
            pass_criteria:
              type: string
              example: "ic_delta_pct > -5.0"
            usage:
              type: string
              example: "awk -F, '$1==\"ic_delta_pct\" && $2 < -5 {exit 1}' /tmp/ic_validation_redundancy_removal.csv"

        analysis_metadata:
          type: object
          properties:
            path:
              type: string
              example: "/tmp/redundancy_analysis_metadata.json"
            format:
              type: string
              example: "JSON"
            schema:
              type: object
              properties:
                timestamp:
                  type: string
                data_specification:
                  type: object
                feature_config:
                  type: object
                thresholds:
                  type: object
                n_features_before:
                  type: integer
                n_features_after:
                  type: integer
                n_redundant_pairs:
                  type: integer

    WorkflowSteps:
      type: object
      description: Sequential steps for redundancy analysis
      properties:
        step_1_data_extraction:
          type: object
          properties:
            description:
              type: string
              example: "Load 3 years of 2h OHLCV data for BTCUSDT, ETHUSDT, SOLUSDT from gapless-crypto-data"
            tool:
              type: string
              example: "gapless_crypto_data.GaplessCryptoDataAdapter"
            output:
              type: string
              example: "/tmp/ohlcv_data_{symbol}.parquet"
            validation:
              type: array
              items:
                type: string
              example:
                - "Verify date range: 2022-10-01 to 2025-09-30"
                - "Verify interval: 2h"
                - "Verify no gaps in timestamp sequence"

        step_2_feature_extraction:
          type: object
          properties:
            description:
              type: string
              example: "Extract 121 multi-interval features for each symbol"
            tool:
              type: string
              example: "atr_adaptive_laguerre.ATRAdaptiveLaguerreRSI.fit_transform_features()"
            config:
              type: object
              properties:
                factory_method:
                  type: string
                  example: "ATRAdaptiveLaguerreRSIConfig.multi_interval(multiplier_1=4, multiplier_2=12)"
            output:
              type: string
              example: "/tmp/features_{symbol}.parquet"
            validation:
              type: array
              items:
                type: string
              example:
                - "Verify n_features == 121"
                - "Verify no NaN values after min_lookback period"
                - "Verify feature_mode == 'multi-interval'"

        step_3_correlation_analysis:
          type: object
          properties:
            description:
              type: string
              example: "Compute Spearman correlation matrix and convert to edge list"
            implementation:
              type: string
              example: |
                corr_matrix = features.corr(method='spearman')
                edges = corr_matrix.stack().reset_index()
                edges.columns = ['feature_1', 'feature_2', 'correlation']
                edges = edges[edges['feature_1'] != edges['feature_2']]
                edges = edges[edges['correlation'].abs() > threshold]
            output:
              type: string
              example: "/tmp/feature_correlations_edgelist.csv"

        step_4_hierarchical_clustering:
          type: object
          properties:
            description:
              type: string
              example: "Hierarchical clustering with Ward linkage, extract flat clusters"
            implementation:
              type: string
              example: |
                from scipy.cluster.hierarchy import linkage, fcluster
                from scipy.spatial.distance import squareform
                distance = 1 - corr_matrix.abs()
                linkage_matrix = linkage(squareform(distance), method='ward')
                clusters = fcluster(linkage_matrix, t=0.3, criterion='distance')
            output:
              type: string
              example: "/tmp/feature_clusters.csv"

        step_5_graph_analysis:
          type: object
          properties:
            description:
              type: string
              example: "NetworkX graph metrics (connected components, degree centrality)"
            implementation:
              type: string
              example: |
                import networkx as nx
                G = nx.from_pandas_edgelist(edges, 'feature_1', 'feature_2', 'correlation')
                metrics = {
                  'connected_components': [list(c) for c in nx.connected_components(G)],
                  'degree_centrality': nx.degree_centrality(G)
                }
            output:
              type: string
              example: "/tmp/graph_metrics.json"

        step_6_redundancy_decisions:
          type: object
          properties:
            description:
              type: string
              example: "Generate actionable decision table for redundant pairs"
            decision_logic:
              type: array
              items:
                type: object
              example:
                - condition: "|ρ| > 0.9"
                  action: "DROP"
                  selection: "Keep feature with higher MI to target (if available) or simpler feature"
                - condition: "0.7 < |ρ| ≤ 0.9"
                  action: "REVIEW"
                  selection: "Manual inspection required"
            output:
              type: string
              example: "/tmp/redundancy_decisions.csv"

        step_7_ic_validation:
          type: object
          properties:
            description:
              type: string
              example: "Validate IC before/after redundancy removal"
            implementation:
              type: string
              example: |
                from atr_adaptive_laguerre import calculate_information_coefficient
                ic_before = calculate_information_coefficient(features_all, target)
                ic_after = calculate_information_coefficient(features_reduced, target)
                delta_pct = 100 * (ic_after - ic_before) / ic_before
            pass_criteria:
              type: string
              example: "ic_delta_pct > -5.0"
            output:
              type: string
              example: "/tmp/ic_validation_redundancy_removal.csv"

    IterativeScreeningWorkflow:
      type: object
      description: Parameterized filtering for threshold refinement
      properties:
        script_path:
          type: string
          example: "/tmp/screen_redundancy.py"
        usage_examples:
          type: array
          items:
            type: string
          example:
            - "python /tmp/screen_redundancy.py 0.8  # Screen at threshold 0.8"
            - "python /tmp/screen_redundancy.py 0.9  # Screen at threshold 0.9"
            - "diff /tmp/filtered_correlations_0.8.csv /tmp/filtered_correlations_0.9.csv"
        script_content:
          type: string
          example: |
            import pandas as pd
            import sys
            threshold = float(sys.argv[1]) if len(sys.argv) > 1 else 0.7
            edges = pd.read_csv('/tmp/feature_correlations_edgelist.csv')
            filtered = edges[edges['correlation'].abs() > threshold]
            print(f"Found {len(filtered)} pairs above threshold {threshold}")
            filtered.to_csv(f'/tmp/filtered_correlations_{threshold}.csv', index=False)

    SLOs:
      type: object
      description: Service Level Objectives for redundancy analysis
      properties:
        availability:
          type: string
          example: "99.9% - Validates all inputs, explicit errors on missing data or invalid configs"
        correctness:
          type: string
          example: "100% - All outputs reproducible, correlations match scipy/pandas reference implementations"
        observability:
          type: string
          example: "Full type hints, structured logging to stdout, all outputs timestamped and metadata-tracked"
        maintainability:
          type: string
          example: "Single-responsibility functions, ≤80 lines per function, no silent fallbacks"

    ErrorHandling:
      type: object
      description: Raise and propagate strategy
      properties:
        data_loading_errors:
          type: array
          items:
            type: string
          example:
            - "ValueError: Symbol {symbol} not found in gapless-crypto-data"
            - "ValueError: Date range {start} to {end} has gaps in {symbol}"
        feature_extraction_errors:
          type: array
          items:
            type: string
          example:
            - "ValueError: Insufficient data: {n_rows} rows provided, {min_lookback} required"
            - "ValueError: Feature count mismatch: expected 121, got {actual}"
        analysis_errors:
          type: array
          items:
            type: string
          example:
            - "ValueError: Correlation matrix contains NaN values"
            - "ValueError: No redundant pairs found above threshold {threshold}"
        validation_errors:
          type: array
          items:
            type: string
          example:
            - "AssertionError: IC validation failed: ic_delta_pct = {delta}% (threshold: -5.0%)"

paths: {}
