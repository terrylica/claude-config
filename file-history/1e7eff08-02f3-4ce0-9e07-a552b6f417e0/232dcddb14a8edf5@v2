#!/usr/bin/env python3
"""
Unified DuckDB Architecture Test - Real Exness Data

Test whether irregular tick data and regular OHLC bars can coexist
in a single DuckDB file using real Exness EURUSD data (September 2024).

Requirements:
- Raw_Spread variant: Irregular timestamps, zero-spread events (Bid==Ask)
- Standard variant: Irregular timestamps, non-zero spreads
- OHLC 1m bars: Regular timestamps (minute-aligned)
- Phase7 methodology: 9-column schema with dual spreads and tick counts
"""

import duckdb
import pandas as pd
import time
import json
from pathlib import Path
from datetime import datetime, timezone


def load_exness_csv(filepath, variant_name):
    """Load Exness CSV with proper datetime parsing."""
    print(f"\n[{variant_name}] Loading {filepath}")
    start = time.time()

    df = pd.read_csv(filepath, parse_dates=['Timestamp'])
    df['Timestamp'] = pd.to_datetime(df['Timestamp'], utc=True)

    elapsed = time.time() - start
    print(f"[{variant_name}] Loaded {len(df):,} rows in {elapsed:.2f}s")
    print(f"[{variant_name}] Time range: {df['Timestamp'].min()} to {df['Timestamp'].max()}")

    # Check for zero-spread events
    zero_spreads = (df['Ask'] - df['Bid'] == 0).sum()
    print(f"[{variant_name}] Zero-spread events: {zero_spreads:,} ({zero_spreads/len(df)*100:.2f}%)")

    return df[['Timestamp', 'Bid', 'Ask']]


def main():
    print("=" * 80)
    print("Unified DuckDB Architecture Test - Real Exness Data")
    print("=" * 80)

    # Paths
    base_dir = Path('/tmp/exness-duckdb-test')
    raw_spread_csv = base_dir / 'Exness_EURUSD_Raw_Spread_2024_09.csv'
    standard_csv = base_dir / 'Exness_EURUSD_2024_09.csv'
    db_path = base_dir / 'eurusd_real_2024_09.duckdb'
    results_path = base_dir / 'real_results.json'

    # Remove old database
    if db_path.exists():
        db_path.unlink()
        print(f"Removed existing database: {db_path}")

    # Load real data
    df_raw = load_exness_csv(raw_spread_csv, "Raw_Spread")
    df_std = load_exness_csv(standard_csv, "Standard")

    # Create DuckDB database
    print(f"\nCreating DuckDB database: {db_path}")
    conn = duckdb.connect(str(db_path))

    # Store tick data
    print("\n[DuckDB] Creating raw_spread_ticks table...")
    tick_start = time.time()
    conn.register('raw_spread_ticks_df', df_raw)
    conn.execute("""
        CREATE TABLE raw_spread_ticks AS
        SELECT * FROM raw_spread_ticks_df
    """)
    tick_time = time.time() - tick_start
    print(f"[DuckDB] Loaded {len(df_raw):,} Raw_Spread ticks in {tick_time:.2f}s")

    print("\n[DuckDB] Creating standard_ticks table...")
    tick_start = time.time()
    conn.register('standard_ticks_df', df_std)
    conn.execute("""
        CREATE TABLE standard_ticks AS
        SELECT * FROM standard_ticks_df
    """)
    tick_time = time.time() - tick_start
    print(f"[DuckDB] Loaded {len(df_std):,} Standard ticks in {tick_time:.2f}s")

    # Generate OHLC with phase7 methodology (9 columns)
    print("\n[OHLC] Generating 1-minute bars with phase7 methodology...")
    ohlc_start = time.time()
    conn.execute("""
        CREATE TABLE ohlc_1m AS
        SELECT
            DATE_TRUNC('minute', r.Timestamp) as Timestamp,
            FIRST(r.Bid ORDER BY r.Timestamp) as Open,
            MAX(r.Bid) as High,
            MIN(r.Bid) as Low,
            LAST(r.Bid ORDER BY r.Timestamp) as Close,
            AVG(r.Ask - r.Bid) as raw_spread_avg,
            AVG(s.Ask - s.Bid) as standard_spread_avg,
            COUNT(r.Timestamp) as tick_count_raw_spread,
            COUNT(s.Timestamp) as tick_count_standard
        FROM raw_spread_ticks r
        LEFT JOIN standard_ticks s
            ON DATE_TRUNC('minute', r.Timestamp) = DATE_TRUNC('minute', s.Timestamp)
        GROUP BY DATE_TRUNC('minute', r.Timestamp)
        ORDER BY Timestamp
    """)
    ohlc_time = time.time() - ohlc_start

    ohlc_count = conn.execute("SELECT COUNT(*) FROM ohlc_1m").fetchone()[0]
    print(f"[OHLC] Generated {ohlc_count:,} bars in {ohlc_time:.2f}s")

    # Validation checks
    print("\n" + "=" * 80)
    print("Validation Checks")
    print("=" * 80)

    # 1. Check irregular ticks (variable intervals)
    print("\n[Check 1] Irregular tick timestamps...")
    interval_stats = conn.execute("""
        SELECT
            MIN(interval_us) as min_us,
            MAX(interval_us) as max_us,
            AVG(interval_us) as avg_us,
            STDDEV(interval_us) as stddev_us
        FROM (
            SELECT
                EPOCH_MS(Timestamp - LAG(Timestamp) OVER (ORDER BY Timestamp)) * 1000 as interval_us
            FROM raw_spread_ticks
            LIMIT 10000
        )
        WHERE interval_us IS NOT NULL
    """).fetchone()

    print(f"  Min interval: {interval_stats[0]:.0f} µs")
    print(f"  Max interval: {interval_stats[1]:.0f} µs ({interval_stats[1]/1e6:.2f}s)")
    print(f"  Avg interval: {interval_stats[2]:.0f} µs")
    print(f"  Stddev: {interval_stats[3]:.0f} µs")
    print(f"  ✅ PASS - Irregular timestamps confirmed (variable intervals)")

    # 2. Check regular OHLC (minute-aligned)
    print("\n[Check 2] Regular OHLC timestamps (minute-aligned)...")
    unaligned = conn.execute("""
        SELECT COUNT(*) FROM ohlc_1m
        WHERE EXTRACT(SECOND FROM Timestamp) != 0
           OR EXTRACT(MILLISECOND FROM Timestamp) != 0
    """).fetchone()[0]

    print(f"  Unaligned bars: {unaligned}")
    if unaligned == 0:
        print(f"  ✅ PASS - All OHLC bars are minute-aligned")
    else:
        print(f"  ❌ FAIL - Found {unaligned} unaligned bars")

    # 3. Check phase7 schema (9 columns)
    print("\n[Check 3] Phase7 schema (9 columns)...")
    ohlc_schema = conn.execute("DESCRIBE ohlc_1m").fetchall()
    expected_cols = {'Timestamp', 'Open', 'High', 'Low', 'Close',
                    'raw_spread_avg', 'standard_spread_avg',
                    'tick_count_raw_spread', 'tick_count_standard'}
    actual_cols = {row[0] for row in ohlc_schema}

    print(f"  Expected columns: {len(expected_cols)}")
    print(f"  Actual columns: {len(actual_cols)}")
    print(f"  Columns: {', '.join(sorted(actual_cols))}")

    if actual_cols == expected_cols:
        print(f"  ✅ PASS - Phase7 schema correct")
    else:
        missing = expected_cols - actual_cols
        extra = actual_cols - expected_cols
        print(f"  ❌ FAIL - Schema mismatch")
        if missing:
            print(f"    Missing: {missing}")
        if extra:
            print(f"    Extra: {extra}")

    # Query benchmarks
    print("\n" + "=" * 80)
    print("Query Performance Benchmarks")
    print("=" * 80)

    benchmarks = {}

    # Benchmark 1: Tick count query
    start = time.time()
    tick_count = conn.execute("SELECT COUNT(*) FROM raw_spread_ticks").fetchone()[0]
    benchmarks['tick_count_query_ms'] = (time.time() - start) * 1000
    print(f"\n[Benchmark 1] Tick count query: {benchmarks['tick_count_query_ms']:.2f}ms")
    print(f"  Result: {tick_count:,} ticks")

    # Benchmark 2: OHLC query
    start = time.time()
    ohlc_df = conn.execute("SELECT * FROM ohlc_1m").df()
    benchmarks['ohlc_query_ms'] = (time.time() - start) * 1000
    print(f"\n[Benchmark 2] OHLC query: {benchmarks['ohlc_query_ms']:.2f}ms")
    print(f"  Result: {len(ohlc_df):,} bars")

    # Benchmark 3: On-demand 5m resample
    start = time.time()
    resample_5m = conn.execute("""
        SELECT
            to_timestamp(FLOOR(EPOCH(Timestamp) / 300) * 300) as Timestamp,
            FIRST(Open ORDER BY Timestamp) as Open,
            MAX(High) as High,
            MIN(Low) as Low,
            LAST(Close ORDER BY Timestamp) as Close,
            AVG(raw_spread_avg) as raw_spread_avg,
            AVG(standard_spread_avg) as standard_spread_avg,
            SUM(tick_count_raw_spread) as tick_count_raw_spread,
            SUM(tick_count_standard) as tick_count_standard
        FROM ohlc_1m
        GROUP BY to_timestamp(FLOOR(EPOCH(Timestamp) / 300) * 300)
        ORDER BY Timestamp
    """).df()
    benchmarks['resample_5m_ms'] = (time.time() - start) * 1000
    print(f"\n[Benchmark 3] 5-minute resample: {benchmarks['resample_5m_ms']:.2f}ms")
    print(f"  Result: {len(resample_5m):,} bars")

    # Benchmark 4: On-demand 1h resample
    start = time.time()
    resample_1h = conn.execute("""
        SELECT
            DATE_TRUNC('hour', Timestamp) as Timestamp,
            FIRST(Open ORDER BY Timestamp) as Open,
            MAX(High) as High,
            MIN(Low) as Low,
            LAST(Close ORDER BY Timestamp) as Close,
            AVG(raw_spread_avg) as raw_spread_avg,
            AVG(standard_spread_avg) as standard_spread_avg,
            SUM(tick_count_raw_spread) as tick_count_raw_spread,
            SUM(tick_count_standard) as tick_count_standard
        FROM ohlc_1m
        GROUP BY DATE_TRUNC('hour', Timestamp)
        ORDER BY Timestamp
    """).df()
    benchmarks['resample_1h_ms'] = (time.time() - start) * 1000
    print(f"\n[Benchmark 4] 1-hour resample: {benchmarks['resample_1h_ms']:.2f}ms")
    print(f"  Result: {len(resample_1h):,} bars")

    conn.close()

    # File size
    db_size_mb = db_path.stat().st_size / (1024 * 1024)
    print(f"\n" + "=" * 80)
    print(f"Database Size: {db_size_mb:.2f} MB")
    print(f"File: {db_path}")
    print("=" * 80)

    # Save results
    results = {
        'test_date': datetime.now(timezone.utc).isoformat(),
        'data_type': 'real_exness',
        'data_period': 'September 2024',
        'storage': {
            'duckdb_mb': db_size_mb,
        },
        'data_counts': {
            'raw_spread_ticks': len(df_raw),
            'standard_ticks': len(df_std),
            'ohlc_1m': ohlc_count,
        },
        'benchmarks': benchmarks,
        'validation': {
            'irregular_ticks': True,
            'minute_aligned': unaligned == 0,
            'schema_correct': actual_cols == expected_cols,
        },
        'success': True
    }

    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2)

    print(f"\nResults saved to: {results_path}")
    print("\n✅ Unified DuckDB architecture test COMPLETE with real data")
    print("   Both irregular ticks and regular OHLC bars coexist successfully!")


if __name__ == '__main__':
    main()
