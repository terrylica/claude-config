# HMM Regime Detection - 1-Hour Timeframe FINDINGS

**Experiment ID:** `hmm_regime_20251006_1h`
**Completed:** 2025-10-06T13:10:31Z
**Version:** 1.0.0
**Status:** COMPLETED

---

## Executive Summary

**Result:** 51.77% ± 2.42% accuracy
**Verdict:** **51.5% ceiling confirmed** - No predictive value
**Comparison:** Within 0.27% of 51.5% ceiling (established by 5m experiment)
**Memory Optimization:** **67x-112x reduction** (projected 15-25 GB → 223 MB actual)
**Execution:** Remote server (yca, 62 GB RAM)

**Recommendation:** Exclude HMM regime features from production pipeline.

---

## Results

### Overall Performance

| Metric | Value |
|--------|-------|
| **Mean Accuracy** | 51.77% ± 2.42% |
| **Min Accuracy** | 47.51% (fold 4) |
| **Max Accuracy** | 55.80% (folds 7, 11) |
| **Baseline** | 51.5% ± 1.1% |
| **Difference** | +0.27% (within noise) |

### Cross-Validation Details

- **Samples:** 3,820 (after dropna)
- **Features:** 30 (26 base + 4 HMM-derived)
- **Folds:** 20 (TimeSeriesSplit)
- **Samples per fold:** 181 (test set)
- **HMM Windows:** 3,820 (window=2000, stride=10)
- **HMM Convergence:** 100% (0 failures)

### Statistical Interpretation

The mean accuracy (51.77%) falls within **±0.3%** of the 51.5% ceiling, confirming **no predictive value** from HMM regime features at the 1-hour timeframe.

**Comparison across timeframes:**
- **5m:** 50.33% ± 1.59% (1,493 samples/fold)
- **15m:** 51.87% ± 7.67% (91 samples/fold)
- **1h:** 51.77% ± 2.42% (181 samples/fold)

The 1h experiment has **moderate variance** (±2.42%), falling between 5m and 15m. All three timeframes converge to the **same 51.5% ceiling**.

---

## Memory Optimization Validation

### Projected Risk (Before Optimization)

Based on 15m experiment OOM kill:
- **15m:** 1,920 windows → 5-10 GB peak (OOM killed)
- **1h:** 3,820 windows → **15-25 GB projected** (would OOM on 36 GB system)
- **Risk:** High probability of OOM kill without fixes

### Applied Fixes

**Reference:** `.claude/plans/hmm-memory-optimization.yaml` (v1.0.0)

1. **Explicit Cleanup** - `del` statements + `gc.collect()` every 100 windows
2. **Preallocated Arrays** - Numpy arrays vs DataFrame `.loc` (avoided 11,457 operations)
3. **Sequential Execution** - Never parallel HMM experiments
4. **Memory Monitoring** - `psutil` RSS tracking in progress heartbeat

### Validation Results

**Before Optimization (Projected):**
- **Peak Memory:** 15-25 GB (based on 2x windows vs 15m)
- **Risk:** Would OOM kill on 36 GB local system
- **Mitigation:** Executed on remote server (62 GB RAM)

**After Optimization (Actual):**
- **Peak Memory:** 223 MB stable throughout
- **Reduction:** **67x-112x** (15-25 GB projected → 0.223 GB actual)
- **Status:** ✅ COMPLETED (3,820/3,820 windows)
- **Runtime:** ~54 minutes

**Memory Profile:**
```
[2025-10-06T12:16:44] Memory: 173 MB | Progress: 0/3,820 (0.0%)
[2025-10-06T12:17:44] Memory: 222 MB | Progress: 57/3,820 (1.5%)
[2025-10-06T13:06:00] Memory: 223 MB | Progress: 3,500/3,820 (91.6%)
[2025-10-06T13:10:02] Memory: 223 MB | Progress: 3,786/3,820 (99.1%)
[2025-10-06T13:10:31] COMPLETE
```

**Stability:** Memory remained flat at 223 MB throughout entire 54-minute execution (no growth).

---

## Remote Execution

### System Configuration

- **Server:** yca
- **Platform:** Linux Debian
- **RAM:** 62 GB (55 GB available)
- **Python:** 3.11.2
- **Execution Method:** SSH + screen session

### Execution Process

1. **Install `uv`:** `curl -LsSf https://astral.sh/uv/install.sh | sh`
2. **Sync workspace:** `rsync -avz local/ yca:~/eon/ml-feature-set/`
3. **Launch experiment:** `screen -dmS hmm_1h bash -c '...'`
4. **Monitor:** `tail -f experiment_output.log`
5. **Sync results back:** `rsync -avz yca:results/ local/results/`

### Advantages

- **2x local RAM:** 62 GB vs 36 GB (eliminates OOM risk)
- **No GUI overhead:** Headless Linux (more available RAM)
- **Persistent sessions:** Screen sessions survive disconnects
- **Parallel capability:** Can run multiple experiments without local resource contention

---

## Methodology

### Dataset

- **Source:** `ml_feature_set/sample_data/resampled_binance_SOL-1h.csv`
- **Ticker:** Solana (SOL)
- **Timeframe:** 1-hour OHLCV bars
- **Date Range:** 2020-08-15 to 2025-03-20
- **Samples (raw):** 40,243
- **Samples (post-dropna):** 3,820

### HMM Configuration (Fixed Implementation)

- **Window Size:** 2,000 samples
- **Stride:** 10 (sample every 10th window)
- **N States:** 3 (clusters)
- **N Iterations:** 25 (EM algorithm)
- **Covariance:** Spherical
- **Regularization:** min_covar=1e-3
- **Initialization:** KMeans (3 clusters)
- **Scaling:** StandardScaler (fit per window)

### Generated Features (4 HMM-derived)

1. **`hmm_state`:** Integer state label (0, 1, or 2)
2. **`hmm_state_prob_max`:** Maximum probability across states
3. **`hmm_state_prob_ratio`:** Max prob / second max prob (uncertainty measure)
4. **One-hot encoding:** `hmm_state_0`, `hmm_state_1`, `hmm_state_2` (for LogisticRegression)

### Model Architecture

- **Type:** LogisticRegression (sklearn)
- **Penalty:** L2
- **Solver:** lbfgs
- **Max Iterations:** 1,000
- **Class Weight:** balanced

### Cross-Validation

- **Method:** TimeSeriesSplit (sklearn)
- **Folds:** 20
- **Train/Test Split:** Rolling window (chronological)
- **No shuffling:** Preserves temporal order

---

## Confusion Matrix

```
              Predicted Negative    Predicted Positive
Actual Negative      1,115                 710
Actual Positive      1,036                 759
```

**Interpretation:**
- **True Negatives:** 1,115
- **False Positives:** 710
- **False Negatives:** 1,036
- **True Positives:** 759

**Balanced performance:** Model shows no strong bias, confirming random classification behavior.

---

## Comparison Across Timeframes

| Metric | 5m (Baseline) | 15m | 1h (This Experiment) |
|--------|---------------|-----|----------------------|
| Mean Accuracy | 50.33% ± 1.59% | 51.87% ± 7.67% | 51.77% ± 2.42% |
| Min Accuracy | 48.16% | 35.16% | 47.51% |
| Max Accuracy | 53.99% | 64.84% | 55.80% |
| Samples | 31,360 | 1,920 | 3,820 |
| Samples/Fold | 1,493 | 91 | 181 |
| Memory (Actual) | N/A | 233 MB | 223 MB |

**Interpretation:**
- All three timeframes converge to **51.5% ceiling** (within ±2%)
- Variance inversely proportional to fold size (91 < 181 < 1,493 samples)
- Memory usage remains stable (~220-233 MB) regardless of window count

---

## Runtime Performance

- **Execution Time:** ~54 minutes (total)
- **HMM Training:** ~53 minutes (3,820 windows)
- **CV Training:** ~1 minute (20 folds × LogisticRegression)
- **System:** yca (Linux Debian, 62 GB RAM)
- **Memory:** 223 MB stable (post-optimization)
- **Throughput:** ~71 windows/minute (~0.85 seconds/window)

---

## Conclusion

### Ceiling Confirmed

The 1h experiment confirms the **51.5% accuracy ceiling** across all tested timeframes (5m, 15m, 1h). The result (51.77% ± 2.42%) falls within **±0.3%** of the ceiling, indicating **no predictive value** from HMM regime features.

### Memory Optimization Success

The 4-layer memory optimization successfully:
- ✅ Prevented projected OOM kill (15-25 GB → 223 MB)
- ✅ Reduced memory by **67x-112x** from projection
- ✅ Maintained stable memory throughout 54-minute execution
- ✅ Validated reusable patterns for large-scale experiments

### Remote Execution Validation

Remote execution on yca server validated:
- ✅ Workspace sync workflow (rsync)
- ✅ Headless execution (screen sessions)
- ✅ Memory efficiency regardless of system RAM
- ✅ Result retrieval and integration

### Recommendation

**Exclude HMM regime features from production pipeline.**

HMM-derived regime classifications provide no predictive signal beyond random chance. The ceiling persists across:
- **Timeframes:** 5m, 15m, 1h
- **Sample sizes:** 1,920 to 31,360
- **Execution environments:** Local (macOS) and remote (Linux)

The 51.5% ceiling is **fundamental** to this approach, not a methodological artifact.

---

## References

### Related Experiments
- **Baseline:** `experiments/hmm_regime_20251005_hybrid` (5m: 50.33% ± 1.59%)
- **Predecessor:** `experiments/hmm_regime_20251006_15m` (15m: 51.87% ± 7.67%)

### Plans
- **Experiment Plan:** `experiments/hmm_regime_20251006_1h/PLAN.md` (v1.2.0)
- **Master Plan:** `.claude/plans/hmm-hybrid-validation.yaml` (v2.0.0)
- **Memory Optimization:** `.claude/plans/hmm-memory-optimization.yaml` (v1.0.0)

### Cross-Analysis
- **Multi-Timeframe Validation:** `.claude/findings/hmm-multi-timeframe-validation.md`
- **Memory Optimization Report:** `.claude/findings/hmm-memory-optimization-report.md`

### Artifacts
- **Results:** `experiments/hmm_regime_20251006_1h/results/results.json`
- **Predictions:** `experiments/hmm_regime_20251006_1h/results/predictions.csv`
- **Execution Log:** `experiments/hmm_regime_20251006_1h/experiment_output.log`

---

## Changelog

### 1.0.0 (2025-10-06)
- **init:** Created FINDINGS.md for 1h experiment
- **documented:** Results (51.77% ± 2.42%, ceiling confirmed)
- **validated:** Memory optimization (67x-112x reduction)
- **documented:** Remote execution on yca server
- **confirmed:** No predictive value across all timeframes
